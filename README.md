# Optimization for Machine Learning - Practical Works

This repository contains practical works completed during the SD-TSIA211 "Optimization for Machine Learning" course at Télécom Paris.

## Course Overview

SD-TSIA211 is a second-year course that provides an introduction to numerical optimization methods, with a focus on applications in data science. The course covers a wide range of fundamental concepts and techniques in optimization, including:

- Convex analysis (convex functions, subdifferential, Legendre-Fenchel transform)
- Gradient descent methods
- Fixed point algorithms
- Proximal gradient descent and line search techniques
- Stochastic gradient descent
- Lagrangian duality
- LASSO problem and its variants
- Optimization for large-scale machine learning problems

The course combines theoretical foundations with practical applications, emphasizing the theorem/proof approach while also exploring techniques for handling massive datasets in statistical learning contexts.

## Practical Works

This repository includes two practical works:

1. **Least Squares and Data Center KPI Prediction**
   - File: `TP_Least_Lquares.ipynb`
   - Topics covered:
     - Reverse-engineering KPIs from data center measurements
     - Implementing and comparing various least squares methods
     - Regularization techniques (L2 and L1)
     - Gradient descent and conjugate gradient methods

2. **Digit Recognition with MNIST Dataset**
   - File: `TP_MNIST_SGD.ipynb`
   - Topics covered:
     - Working with the MNIST dataset
     - Implementing a neural network model using Keras
     - Stochastic Gradient Descent (SGD) implementation
     - Batch processing in SGD
     - Model evaluation on training and test sets

## Technologies Used

- Python
- NumPy
- SciPy
- Matplotlib
- TensorFlow
- Keras

## How to Use

Each practical work is accompanied by a PDF file containing instructions and questions. The corresponding code implementations can be found in Jupyter notebooks or Python scripts within this repository.

## Note

These practical works were completed as part of the coursework and are intended for educational purposes. They demonstrate the application of optimization techniques to real-world machine learning problems.